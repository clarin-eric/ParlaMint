ParlaMint-GB_2020-02-12-lords.u1	My Lords, I notify the House of the retirement with effect from today of the noble Lord, Lord Elystan-Morgan, pursuant to Section 1 of the House of Lords Reform Act 2014. On behalf of the House, I thank the noble Lord for his much-valued service to this House.
ParlaMint-GB_2020-02-12-lords.u2	To ask Her Majesty’s Government what progress has been made in reducing the disability employment gap.
ParlaMint-GB_2020-02-12-lords.u173	My Lords, I am only too glad to add my word of thanks to the humble, ordinary, flesh-and-blood noble Lord, Lord Clement-Jones, for our debate this evening. So many points have been raised, many of them the object of concern of more than one contributor to the debate. I am reminded a little of what happened when we had the big bang in the 1980s: finance went global and clever young people knew how to construct products within the financial sector that their superiors and elders had no clue about. Something like that is happening now, which makes it even more important for us to be aware and ready to deal with it I take up the point raised by the noble Lord, Lord Browne of Ladyton, about legislation. He said that it had to be flexible; I would add “nimble”. We must have the general principles of what we want to do to regulate this area available to us, but be ready to act immediately—as and when circumstances require it—instead of taking cumbersome pieces of legislation through all stages in both Houses. The movement is much faster than that in the real world. I recognise what has been said about the exponential scale in the advance of all these methodologies and approaches. We heard ample mention of the Nolan principles; I am glad about that On the right of explanation, I picked up an example that it is worth reminding ourselves of when we ask what it means to have an explanation of what is happening. It comes from Italy; perhaps other Members will be aware of it too. An algorithm was used to decide into which schools to send state schoolteachers. After some dubious decision-making by the algorithm, teachers had to fight through the courts to get some sort of transparency regarding the instructions that the algorithm had originally been given. Although the teachers wanted access to the source code of the algorithm—the building blocks, with all the instructions —the Italian Supreme Court ruled that appropriate transparency constituted only an explanation of its function and the underlying legal rules. In other words, it did not give the way in which the method was evolved or the algorithm formed; it was just descriptive rather than analytical. I believe that, if we want transparency, we have to make available the kind of its nuts-and-bolts aspects that lead to the algorithms that are then the object of our concern On accountability, who can call the shots? The noble Baroness, Lady Rock, was one of those who mentioned that. I have been reading, because it is coming up, the Government’s online harms response and the report of the House of Commons Science and Technology Committee. I am really in double-Dutch land with it all as I look at how they interleave with each other. Each says things separately and yet together. In the report that I think we will be looking at tomorrow, it is recommended that we should continue to use the good offices of the ICO to cover the way in which the online harms process is taken forward. We have also heard that that may be the appropriate body to oversee all the things that we have been discussing. While the Information Commissioner’s Office is undoubtedly brilliant and experienced, is it really the only regulator that can handle this multiplicity of tasks? Is there a need now to look at perhaps adding something in to recognise the speed at which these things are developing—to say nothing of appointing, as the report suggests, a Minister with responsibility for this area I am so glad to see the noble Lord, Lord Ashton, arrive in his new guise as Chief Whip, because, in a previous incarnation, we were eyeball to eyeball like this. He reminds me of course that it was on the Data Protection Bill, as it then was—an enormous, composite, huge thing—that I cut my teeth, swimming against the tide and wondering whether I would drown. It was said then that the Centre for Data Ethics and Innovation was something we should aim at. It needs to happen. Here we are, two years later, and it still has not happened; it is still an aspiration. We must move forward to a competent body that can look at the ethical dimensions of these developments. It must have teeth and it must make recommendations, and it must do so speedily. On that, I am simply repeating what others have said. Let me finish with one word—it will go into Hansard; it will go against my reputation and I will be a finished man after saying it. When I put my computer on with certain of the things that I do—for example, the Guardian quick crossword, which is part of my morning devotions—the advertising that comes up presumably has been put there by an algorithm. But it suggests that I want to buy women’s underwear. I promise noble Lords that I have no experience in that area at all, and I want to know, as a matter of transparency, what building blocks have gone into the algorithm that has told my computer to interest me in these rather recondite aspects of womenswear.
ParlaMint-GB_2020-02-12-lords.u174	My Lords, I am lost for words. I am really not sure how one follows that disclosure I echo other noble Lords in thanking the noble Lord, Lord Clement-Jones, for securing this important and interesting debate. I think that I am with the noble Lord, Lord Browne of Ladyton, in being the only outcasts who were not on any of the committees—the noble Lord, Lord Griffiths, indicates that he was not either—so we are an elite club The noble Lord, Lord Clement-Jones, rightly highlighted the widespread and rapidly growing use of algorithms, which underlines the importance of this debate. As noble Lords are aware, the UK is a world leader in relation to artificial intelligence, in terms of attracting investment, attracting talent and, crucially, in thinking through the practical and ethical challenges that the technology presents While driving forward innovation, we need to ensure that we maintain the public’s trust in how decisions are made about them and how their data is used, thus ensuring fairness, avoiding bias and offering transparency and accountability—which are all aspirations that noble Lords have expressed We want to maximise the potential that artificial intelligence offers, while ensuring that any negative implications of its use are mitigated. The Government have introduced a number of measures and interventions to ensure that we maintain public trust, something underlined by my noble friend Lady Rock, in the use of these technologies in the public sector. These include setting up the Centre for Data Ethics and Innovation; developing a data ethics framework and a guide to using artificial intelligence; and creating a draft set of guidelines for AI procurement. To be successful, we need practice to become standardised, consistent and accountable. If so, public services have the potential, as my noble friend Lord Holmes pointed out, to become much fairer than they have been historically. I think it was the noble Lord, Lord Wallace, who said—forgive me if I have got this wrong—that we have to realise that potential Several noble Lords talked about the report from the Committee on Standards in Public Life, Artificial Intelligence and Public Standards. The Government have noted the recommendations on greater transparency by public bodies in the use of algorithms; new guidance to ensure that algorithmic decision-making abides by equalities law, which obviously applies in just the same way as in any other context; the creation of a single, coherent regulatory framework to govern this area; the formation of a statutory body to advise existing regulators on relevant issues; and proper routes of redress for citizens who feel that decisions are unfair. The Government will respond to these recommendations in due course, and that may offer another opportunity to reflect on these issues We also welcome the committee’s recommendation relating to the Centre for Data Ethics and Innovation. We were very pleased to see the committee’s endorsement of the centre’s important role in identifying gaps in the regulatory landscape. We are discussing with the centre the statutory powers it thinks it will need—a point made by the noble Lord, Lord Giddens—to deliver against those terms of reference. The right reverend Prelate the Bishop of Oxford expressed the need for a set of principles and an ethical basis for all our work. Noble Lords will be aware of the development of the data ethics framework, which includes a number of those principles. We are currently working on refreshing that framework to make it as up to date as possible for public servants who work with data The Committee on Standards in Public Life report, and others, have raised the issue of multiple frameworks. The Government are currently looking into developing a landing page on GOV.UK to enable users to assess the different frameworks and direct them to the one that is most appropriate and relevant to their needs. A number of noble Lords raised the importance of any framework staying agile and nimble. That is absolutely right. There is a lot more work to do on this, including looking at defining high-stakes algorithms and thinking through the mechanisms to ensure that decisions are made in an objective way. In that agility, I think all noble Lords would agree that we want to stay anchored to those key ethical principles, including, of course, the Nolan principles One of the foundations of our approach is the work being done on having a clear ethical framework, but we also need sound ways of implementing in practice the principles expressed in the framework. Part of our work in trying to increase transparency and accountability in the use of algorithms in AI has been the collaboration between the Office for Artificial Intelligence and the World Economic Forum’s Centre for the Fourth Industrial Revolution to codesign guidelines for AI procurement to unlock AI adoption in the public sector We published the draft guidelines for consultation in September 2019. The Office for Artificial Intelligence is now collaborating with other government departments to test those findings and proposals and has launched a series of pilots of the guidelines, including with four or five major government departments. Following the pilot and consultation phase, we will update the guidelines and work to design what only government could call an “AI procurement in a box” toolkit to provide other Governments and our public sector agencies with the tools they need to have the highest standards of procurement In an effort to bring coherence across central government departments, my honourable friend the Minister for Digital and Broadband and my right honourable friend the Minister for Universities, Science, Research and Innovation wrote a letter earlier this week to all Secretaries of State reminding them of and highlighting the work of the AI Council and the support it can give government departments The noble Lord, Lord Giddens, asked about the Alan Turing Institute. The Government value its work greatly, particularly some of the work being done around skills development, which is so critical in this field I think every noble Lord spoke about algorithmic bias. My noble friend Lord Taylor spoke about facial recognition and issues particularly among police forces. Other noble Lords referred to the work of DWP and child protection agencies. It is important that our work in trying to avoid bias—I think all noble Lords recognise that bias exists potentially within algorithms but also in more traditional decision-making—is guided by independent and expert advice. Again, we are grateful to the Centre for Data Ethics and Innovation, which as part of its current work programme is conducting a review into the potential for bias, looking particularly at policing, financial services, recruitment—this was referred to by the noble Lord, Lord Addington; I note how lucky it is that my noble friends Lady Rock and Lady Chisholm and I managed to beat the recruitment algorithm to get here—and local government. These sectors were all selected because they involve significant decisions being made about individuals. The report will be published in March and we very much look forward to its recommendations, which will inform our work in future I fear that I will have to write on some of the points raised, but I will do my best to cover as many as I can in the remaining time. The noble Lord, Lord St John, asked about having a duty on public bodies to declare where they are using algorithms. We hope the Centre will be looking at all of these things in the transparency aspect of its work. We are also currently reviewing the future work plan with the Centre, and obviously a number of the issues around accountability will be discussed as part of that In closing, I will go back to two points. One is on the potential of the use of artificial intelligence, which PricewaterhouseCoopers has estimated could contribute almost $16 trillion to the global economy; obviously the UK is one of the top three countries providing that, so that would be a huge boost to our economy. However, I also go back to what the right reverend Prelate the Bishop of Oxford said about what it means to be human. We can harness that potential in a way that enhances, rather than erodes, our humanity.
